def scratch_dir =   System.getenv("VSC_SCRATCH_PROJECTS_BASE") ? "${System.getenv("VSC_SCRATCH_PROJECTS_BASE")}/${params.tier1_project}" : // Tier 1 scratch
                    System.getenv("VSC_SCRATCH_VO_USER") ?: // VO scratch
                    System.getenv("VSC_SCRATCH") // user scratch

// Specify the work directory
workDir = "$scratch_dir/work"

// Perform work directory cleanup when the run has succesfully completed
cleanup = true

singularity {
    enabled = true
    autoMounts = true
    cacheDir = "$scratch_dir/singularity"
}
 
env {
    APPTAINER_TMPDIR="$scratch_dir/.apptainer/tmp"
    APPTAINER_CACHEDIR="$scratch_dir/.apptainer/cache"
}

process {
  // Global process config
  executor = 'local' //change to pbs if you want to sent jobs instead
}

executor {
  // How many jobs do we run in parallel?
  queueSize = 50
  submitRateLimit = '30/1min'
  exitReadTimeout = "3day"
}

// Add backoff strategy to catch cluster timeouts and proper symlinks of files in scratch to the work directory
process {
    stageInMode = "symlink"
    stageOutMode = "rsync"
    errorStrategy = { sleep(Math.pow(2, task.attempt ?: 1) * 200 as long); return 'retry' }
    maxRetries    = 5
}

// Process-specific resource requirements
process {  
  withLabel:plots {
    beforeScript = 'module load R-bundle-Bioconductor/3.15-foss-2022a-R-4.2.1'
    cpus =  2
    memory = 64.GB
    time = 30.min
  }
  withLabel:low {
    cpus =  2
    memory = 64.GB
    time = 30.min
  }
  withLabel:med {
    cpus = 4
    cpus = 2
    memory = 100.GB
    time = 1.h
  }
  withLabel:high {
    beforeScript = 'module load PyTorch/1.12.0-foss-2022a-CUDA-11.7.0'
    memory = 100.GB
    time = 4.h
    cpus = 4
    clusterOptions = {"-l gpus=4:ppn=${task.cpus}"}
		ext.args = "--num-gpus 4"
  }
}

includeConfig "$projectDir/Params.config"
plugins {
  id 'nf-validation'
}


